simple_cnn.py
import torch
import torch.nn as nn
import torch.optim as optim
import argparse
from tqdm import tqdm
from dataloader import get_data_loaders
import torchvision.transforms as transforms
import torch.nn.functional as F


class SimpleCNN(nn.Module):
    def __init__(self, num_classes=5):
        super(SimpleCNN, self).__init__()

        # Convolutional layers maintaing color channels
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(
            in_channels=16, out_channels=32, kernel_size=3, padding=1
        )

        # Max pooling layer
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

        # Fully connected layers
        self.fc1 = nn.Linear(32 * 32 * 32, 128)
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        # pooling layers
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))

        # Flatten
        x = x.view(-1, 32 * 32 * 32)

        # Fully connected layers with ReLU activation
        x = F.relu(self.fc1(x))
        x = self.fc2(x)

        return x


def train_model(train_loader, model, criterion, optimizer, num_epochs, device):
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()

            outputs = model(images)

            loss = criterion(outputs, labels)

            # Backward pass and optimize
            loss.backward()
            optimizer.step()

            # Update running loss and accuracy
            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        epoch_loss = running_loss / len(train_loader)
        epoch_acc = 100 * correct / total
        print(
            f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%"
        )


def main(args):
    model = SimpleCNN(num_classes=5)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    model = model.to(device)

    # Loss function and optimizer
    criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification
    optimizer = optim.Adam(model.parameters(), lr=args.lr)

    # Apply data transformations
    transform = transforms.Compose(
        [
            transforms.Resize((128, 128)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )

    train_loader, valid_loader, test_loader = get_data_loaders(
        args.batch_size, transform
    )

    train_model(train_loader, model, criterion, optimizer, args.epochs, device)

    torch.save(model.state_dict(), "simple_cnn.pth")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Fruit Image Classification with Simple CNN"
    )

    parser.add_argument(
        "--epochs", type=int, default=10, help="Number of training epochs"
    )
    parser.add_argument("--lr", type=float, default=0.001, help="Learning rate")
    parser.add_argument(
        "--batch_size", type=int, default=32, help="Batch size for training"
    )

    args = parser.parse_args()

    main(args)
Using device: cpu
Epoch [1/10], Loss: 1.1973, Accuracy: 50.71%
Epoch [2/10], Loss: 0.9304, Accuracy: 62.83%
Epoch [3/10], Loss: 0.7019, Accuracy: 73.74%
Epoch [4/10], Loss: 0.4120, Accuracy: 85.46%
Epoch [5/10], Loss: 0.1802, Accuracy: 94.53%
Epoch [6/10], Loss: 0.0885, Accuracy: 97.53%
